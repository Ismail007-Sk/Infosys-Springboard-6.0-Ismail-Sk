{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "442d5f2a-b291-4e49-86da-0137c2872132",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# NLP MODELS COMPARISON SCRIPT\n",
    "BoW vs TF-IDF vs Word2Vec \n",
    "- All three are text-based embedding/feature extraction methods.\n",
    "- GridSearchCV for C (LogisticRegression) and alpha (MultinomialNB)\n",
    "    - C → hyperparameter of LogisticRegression\n",
    "    - alpha → hyperparameter of MultinomialNB\n",
    "    - GridSearchCV → finds the best values for these hyperparameters.\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c698e8e-374e-4ca8-add5-01e3ff4667b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# IMPORTING REQUIRED PACKAGES\n",
    "# ============================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# For Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize   # if not installed: pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)   #punkt is NLTK’s pretrained sentence and word tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f629823e-1479-4c8f-b79d-5f9ce45c7638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ratings         Comment                                            Reviews\n",
      "0        5          Super!  Great camera for pics and videos Battery life ...\n",
      "1        5       Must buy!  Great device. Let me tell the Pros..1. Superb ...\n",
      "2        5   Great product  Who all loves older size i.e., 4.7 inch type s...\n",
      "3        5  Simply awesome  This iPhone SE is the best phone ever you get....\n",
      "4        5  Classy product  This is my second iphone after iphone 4s. I’ve...\n"
     ]
    }
   ],
   "source": [
    "# ===================\n",
    "# 1. LOAD  DATASET \n",
    "# ===================\n",
    "\n",
    "df = pd.read_csv(r\"E:\\3rd YEAR CSE(AI-ML)\\5thsem\\Machine Learning\\ISMAIL\\APPLE_iPhone_SE.csv\")  \n",
    "print(df.head())\n",
    "\n",
    "texts = df[\"Reviews\"].astype(str).values\n",
    "labels = df[\"Ratings\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e528fd5-0e9d-4ce5-bcab-66b4742b3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 2. TRAIN / TEST SPLIT\n",
    "# ======================\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe80ecb-1ba9-43b9-94da-e959df6b3aab",
   "metadata": {},
   "source": [
    "# Text: \"I love NLP\"\n",
    "    - ngram (1,1): \"I\", \"love\", \"NLP\" → 3 features\n",
    "    - ngram (1,3): \"I\", \"love\", \"NLP\", \"I love\", \"love NLP\", \"I love NLP\" → 6+ features\n",
    "\n",
    "More n-grams = more features = bigger model = higher risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8349cd-df49-4278-aab1-8a2c9f547e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Explosion Demo with CountVectorizer ===\n",
      "BoW ngram_range=(1,1) -> shape: (7770, 6808)\n",
      "BoW ngram_range=(1,3) -> shape: (7770, 142178)\n",
      "Note: Same samples, many more features -> feature explosion, risk of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# 3. FEATURE EXPLOSION: ngram_range=(1,1) vs (1,3)\n",
    "# =====================================\n",
    "\n",
    "print(\"\\n=== Feature Explosion Demo with CountVectorizer ===\")\n",
    "bow_11 = CountVectorizer(ngram_range=(1, 1))\n",
    "X_train_bow_11 = bow_11.fit_transform(X_train_text)\n",
    "print(\"BoW ngram_range=(1,1) -> shape:\", X_train_bow_11.shape)\n",
    "\n",
    "bow_13 = CountVectorizer(ngram_range=(1, 3))\n",
    "X_train_bow_13 = bow_13.fit_transform(X_train_text)\n",
    "print(\"BoW ngram_range=(1,3) -> shape:\", X_train_bow_13.shape)\n",
    "print(\"Note: Same samples, many more features -> feature explosion, risk of overfitting.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e847fa60-fe26-4325-9ff1-0d14abfced3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GridSearchCV: Logistic Regression + BoW ===\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best params (LR + BoW): {'clf__C': 0.1, 'vect__ngram_range': (1, 3)}\n",
      "Best CV accuracy: 0.7120978120978121\n",
      "Test accuracy (LR + BoW): 0.7159032424086464\n",
      "Classification report (LR + BoW):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.34      0.43        95\n",
      "           2       0.50      0.03      0.05        40\n",
      "           3       0.38      0.05      0.08       107\n",
      "           4       0.34      0.12      0.17       343\n",
      "           5       0.75      0.97      0.84      1358\n",
      "\n",
      "    accuracy                           0.72      1943\n",
      "   macro avg       0.51      0.30      0.31      1943\n",
      "weighted avg       0.64      0.72      0.65      1943\n",
      "\n",
      "\n",
      "=== GridSearchCV: Logistic Regression + TF-IDF ===\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best params (LR + TF-IDF): {'clf__C': 1, 'vect__ngram_range': (1, 1)}\n",
      "Best CV accuracy: 0.7106821106821107\n",
      "Test accuracy (LR + TF-IDF): 0.7138445702521874\n",
      "Classification report (LR + TF-IDF):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.34      0.42        95\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.50      0.05      0.09       107\n",
      "           4       0.30      0.09      0.14       343\n",
      "           5       0.74      0.97      0.84      1358\n",
      "\n",
      "    accuracy                           0.71      1943\n",
      "   macro avg       0.42      0.29      0.30      1943\n",
      "weighted avg       0.63      0.71      0.64      1943\n",
      "\n",
      "\n",
      "=== GridSearchCV: MultinomialNB + BoW ===\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best params (NB + BoW): {'clf__alpha': 1.0, 'vect__ngram_range': (1, 1)}\n",
      "Best CV accuracy: 0.7075933075933075\n",
      "Test accuracy (NB + BoW): 0.7045805455481214\n",
      "Classification report (NB + BoW):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.20      0.29        95\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.00      0.00      0.00       107\n",
      "           4       0.30      0.12      0.17       343\n",
      "           5       0.74      0.96      0.84      1358\n",
      "\n",
      "    accuracy                           0.70      1943\n",
      "   macro avg       0.32      0.26      0.26      1943\n",
      "weighted avg       0.60      0.70      0.63      1943\n",
      "\n",
      "\n",
      "=== GridSearchCV: MultinomialNB + TF-IDF ===\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best params (NB + TF-IDF): {'clf__alpha': 0.1, 'vect__ngram_range': (1, 1)}\n",
      "Best CV accuracy: 0.7024453024453026\n",
      "Test accuracy (NB + TF-IDF): 0.7061245496654658\n",
      "Classification report (NB + TF-IDF):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.22      0.32        95\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.14      0.01      0.02       107\n",
      "           4       0.32      0.08      0.13       343\n",
      "           5       0.73      0.97      0.83      1358\n",
      "\n",
      "    accuracy                           0.71      1943\n",
      "   macro avg       0.36      0.26      0.26      1943\n",
      "weighted avg       0.60      0.71      0.62      1943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# 4. GRIDSEARCHCV: LOGISTIC REGRESSION & MULTINOMIAL NB\n",
    "#    WITH BoW AND TF-IDF\n",
    "#    BoW / TF-IDF → simple statistical embeddings\n",
    "# =====================================\n",
    "\n",
    "# --------- (A) Logistic Regression + CountVectorizer(BOW) ---------\n",
    "pipe_lr_bow = Pipeline([\n",
    "    (\"vect\", CountVectorizer()),   # default ngram_range=(1,1)\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "param_grid_lr_bow = {\n",
    "    \"vect__ngram_range\": [(1,1), (1,2), (1,3)],   # to observe effect of higher n-grams\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_lr_bow = GridSearchCV(\n",
    "    estimator=pipe_lr_bow,\n",
    "    param_grid=param_grid_lr_bow,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=== GridSearchCV: Logistic Regression + BoW ===\")\n",
    "grid_lr_bow.fit(X_train_text, y_train)\n",
    "print(\"Best params (LR + BoW):\", grid_lr_bow.best_params_)\n",
    "print(\"Best CV accuracy:\", grid_lr_bow.best_score_)\n",
    "\n",
    "best_lr_bow = grid_lr_bow.best_estimator_\n",
    "y_pred_lr_bow = best_lr_bow.predict(X_test_text)\n",
    "print(\"Test accuracy (LR + BoW):\", accuracy_score(y_test, y_pred_lr_bow))\n",
    "print(\"Classification report (LR + BoW):\\n\", classification_report(y_test, y_pred_lr_bow))\n",
    "\n",
    "\n",
    "# --------- (B) Logistic Regression + TfidfVectorizer(TF-IDF) ---------\n",
    "pipe_lr_tfidf = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "param_grid_lr_tfidf = {\n",
    "    \"vect__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_lr_tfidf = GridSearchCV(\n",
    "    estimator=pipe_lr_tfidf,\n",
    "    param_grid=param_grid_lr_tfidf,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== GridSearchCV: Logistic Regression + TF-IDF ===\")\n",
    "grid_lr_tfidf.fit(X_train_text, y_train)\n",
    "print(\"Best params (LR + TF-IDF):\", grid_lr_tfidf.best_params_)\n",
    "print(\"Best CV accuracy:\", grid_lr_tfidf.best_score_)\n",
    "\n",
    "best_lr_tfidf = grid_lr_tfidf.best_estimator_\n",
    "y_pred_lr_tfidf = best_lr_tfidf.predict(X_test_text)\n",
    "print(\"Test accuracy (LR + TF-IDF):\", accuracy_score(y_test, y_pred_lr_tfidf))\n",
    "print(\"Classification report (LR + TF-IDF):\\n\", classification_report(y_test, y_pred_lr_tfidf))\n",
    "\n",
    "\n",
    "# --------- (C) MultinomialNB + CountVectorizer(BOW) ---------\n",
    "pipe_nb_bow = Pipeline([\n",
    "    (\"vect\", CountVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "param_grid_nb_bow = {\n",
    "    \"vect__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "    \"clf__alpha\": [0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "}\n",
    "\n",
    "grid_nb_bow = GridSearchCV(\n",
    "    estimator=pipe_nb_bow,\n",
    "    param_grid=param_grid_nb_bow,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== GridSearchCV: MultinomialNB + BoW ===\")\n",
    "grid_nb_bow.fit(X_train_text, y_train)\n",
    "print(\"Best params (NB + BoW):\", grid_nb_bow.best_params_)\n",
    "print(\"Best CV accuracy:\", grid_nb_bow.best_score_)\n",
    "\n",
    "best_nb_bow = grid_nb_bow.best_estimator_\n",
    "y_pred_nb_bow = best_nb_bow.predict(X_test_text)\n",
    "print(\"Test accuracy (NB + BoW):\", accuracy_score(y_test, y_pred_nb_bow))\n",
    "print(\"Classification report (NB + BoW):\\n\", classification_report(y_test, y_pred_nb_bow))\n",
    "\n",
    "\n",
    "# --------- (D) MultinomialNB + TfidfVectorizer(TF-IDF) ---------\n",
    "pipe_nb_tfidf = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "param_grid_nb_tfidf = {\n",
    "    \"vect__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "    \"clf__alpha\": [0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "}\n",
    "\n",
    "grid_nb_tfidf = GridSearchCV(\n",
    "    estimator=pipe_nb_tfidf,\n",
    "    param_grid=param_grid_nb_tfidf,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== GridSearchCV: MultinomialNB + TF-IDF ===\")\n",
    "grid_nb_tfidf.fit(X_train_text, y_train)\n",
    "print(\"Best params (NB + TF-IDF):\", grid_nb_tfidf.best_params_)\n",
    "print(\"Best CV accuracy:\", grid_nb_tfidf.best_score_)\n",
    "\n",
    "best_nb_tfidf = grid_nb_tfidf.best_estimator_\n",
    "y_pred_nb_tfidf = best_nb_tfidf.predict(X_test_text)\n",
    "print(\"Test accuracy (NB + TF-IDF):\", accuracy_score(y_test, y_pred_nb_tfidf))\n",
    "print(\"Classification report (NB + TF-IDF):\\n\", classification_report(y_test, y_pred_nb_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67363fcb-45ce-4917-bd02-67a4546adcee",
   "metadata": {},
   "source": [
    "\n",
    "# =====================================\n",
    "- CountVectorizer/TfidfVectorizer → scikit-learn pipeline (compatible with GridSearchCV)\n",
    "- Word2Vec → gensim model → not compatible with GridSearchCV pipelines\n",
    "\n",
    "MultinomialNB requires:\n",
    "   - non-negative values\n",
    "   - word counts or frequencies\n",
    "\n",
    "But Word2Vec gives:\n",
    "   - dense vectors\n",
    "   - negative values\n",
    "   - continuous semantic embeddings\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff464909-faa1-49b0-ac5a-136c30f5334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Word2Vec Averaged Embeddings + Logistic Regression ===\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best params (LR + Word2Vec): {'C': 10}\n",
      "Best CV accuracy: 0.705920205920206\n",
      "Test accuracy (LR + Word2Vec): 0.6999485331960885\n",
      "Classification report (LR + Word2Vec):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.21      0.27        95\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.19      0.03      0.05       107\n",
      "           4       0.25      0.04      0.07       343\n",
      "           5       0.73      0.97      0.83      1358\n",
      "\n",
      "    accuracy                           0.70      1943\n",
      "   macro avg       0.31      0.25      0.25      1943\n",
      "weighted avg       0.58      0.70      0.61      1943\n",
      "\n",
      "\n",
      "=== LinearSVC + TF-IDF (baseline) ===\n",
      "Test accuracy (LinearSVC + TF-IDF): 0.716932578486876\n",
      "Classification report (LinearSVC + TF-IDF):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.56      0.58        95\n",
      "           2       0.44      0.10      0.16        40\n",
      "           3       0.33      0.12      0.18       107\n",
      "           4       0.31      0.16      0.21       343\n",
      "           5       0.78      0.93      0.85      1358\n",
      "\n",
      "    accuracy                           0.72      1943\n",
      "   macro avg       0.49      0.38      0.40      1943\n",
      "weighted avg       0.66      0.72      0.67      1943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# 5. WORD2VEC AVERAGED EMBEDDINGS + LOGISTIC REGRESSION\n",
    "#    Word2Vec → learned embeddings using CBOW or Skip-Gram (sg=1)\n",
    "\n",
    "    #Because Word2Vec already produces numeric vectors → so only the classifier (LR) needs hyperparameter tuning.\n",
    "    #Naive Bayes cannot be used on Word2Vec vectors.\n",
    "# =====================================\n",
    "\n",
    "\n",
    "print(\"\\n=== Word2Vec Averaged Embeddings + Logistic Regression ===\")\n",
    "\n",
    "# ---- Tokenize sentences ----\n",
    "X_train_tokens = [word_tokenize(doc.lower()) for doc in X_train_text]\n",
    "X_test_tokens = [word_tokenize(doc.lower()) for doc in X_test_text]\n",
    "\n",
    "# ---- Train Word2Vec on training data ----\n",
    "w2v_dim = 100\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=X_train_tokens,\n",
    "    vector_size=w2v_dim,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1  # skip-gram\n",
    ")\n",
    "\n",
    "# ---- Helper: sentence to averaged vector ----\n",
    "def sentence_to_vec(tokens, model, dim):\n",
    "    vecs = []\n",
    "    for w in tokens:\n",
    "        if w in model.wv:\n",
    "            vecs.append(model.wv[w])\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros(dim)\n",
    "    else:\n",
    "        return np.mean(vecs, axis=0)\n",
    "\n",
    "X_train_w2v = np.array([sentence_to_vec(tokens, w2v_model, w2v_dim) for tokens in X_train_tokens])\n",
    "X_test_w2v = np.array([sentence_to_vec(tokens, w2v_model, w2v_dim) for tokens in X_test_tokens])\n",
    "\n",
    "# ---- GridSearchCV for Logistic Regression on Word2Vec features ----\n",
    "lr_w2v = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "\n",
    "param_grid_lr_w2v = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_lr_w2v = GridSearchCV(\n",
    "    estimator=lr_w2v,\n",
    "    param_grid=param_grid_lr_w2v,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_lr_w2v.fit(X_train_w2v, y_train)\n",
    "print(\"Best params (LR + Word2Vec):\", grid_lr_w2v.best_params_)\n",
    "print(\"Best CV accuracy:\", grid_lr_w2v.best_score_)\n",
    "\n",
    "best_lr_w2v = grid_lr_w2v.best_estimator_\n",
    "y_pred_w2v = best_lr_w2v.predict(X_test_w2v)\n",
    "print(\"Test accuracy (LR + Word2Vec):\", accuracy_score(y_test, y_pred_w2v))\n",
    "print(\"Classification report (LR + Word2Vec):\\n\", classification_report(y_test, y_pred_w2v))\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 6. OPTIONAL: LINEARSVC FOR COMPARISON (BoW/TFIDF)\n",
    "# =====================================\n",
    "\n",
    "# Simple example: LinearSVC + TF-IDF (no grid search, just baseline)\n",
    "pipe_svc_tfidf = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(ngram_range=(1,2))),\n",
    "    (\"clf\", LinearSVC(max_iter=10000))\n",
    "])\n",
    "\n",
    "pipe_svc_tfidf.fit(X_train_text, y_train)\n",
    "y_pred_svc = pipe_svc_tfidf.predict(X_test_text)\n",
    "print(\"\\n=== LinearSVC + TF-IDF (baseline) ===\")\n",
    "print(\"Test accuracy (LinearSVC + TF-IDF):\", accuracy_score(y_test, y_pred_svc))\n",
    "print(\"Classification report (LinearSVC + TF-IDF):\\n\", classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedd38c-464b-45a6-9cb8-cf0eaab79f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
